{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8cd761a-e8dd-4f11-bafe-463b060737d5",
   "metadata": {},
   "source": [
    "# Rechunk Kyoko's CONUS404 output\n",
    "Rechunk only variables contained in the DRB spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f68b0-6859-46d9-b79e-e3c6ba6513c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rechunker\n",
    "import zarr\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc404a-1ef0-4d80-9a99-6c181a7cd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783429b-429e-4b2c-8b45-6901402fe4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a647e5-ca81-4a48-8a2d-8768559b8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nhm-usgs/data-pipeline-helpers/main/conus404/wrf2d_vars_drb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df368ef-6d85-4b5e-8e21-a5fa2296e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = df['variable'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c8c1d-28de-45dd-bfa5-8a7253bf1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4fdf5-26d0-4c25-be11-3ad395cf1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125565be-4bdd-4d3f-a2c2-61e5e7d3a398",
   "metadata": {},
   "source": [
    "#### Create a list of 2D files for one water year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054c9b4-ef02-4712-89ee-7831b1b79cf6",
   "metadata": {},
   "source": [
    "Use fsspec for file operations, even though we are on a local file system.  If we use fsspec for everything (local files, https, s3, gcs) it leads to less code changes when we switch between these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e482a7-4316-4fc5-bfc6-60a8d48dbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54657e8-2c47-4502-a20a-117524b77c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = sorted(fs.glob('/caldera/projects/usgs/water/impd/wrf-conus404/kyoko/wrfout_post/WY2017/wrf2d_d01*'))\n",
    "print(flist[0])\n",
    "print(flist[-1])\n",
    "len(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db022316-2a34-4629-9762-86ac94316356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204dcc2-f662-455f-9d79-d0c3a020aa7c",
   "metadata": {},
   "source": [
    "There is a useful environment variable called `SLURM_CLUSTER_NAME` that indicates whether we are on Denali or Tallgrass.  If the code bombs with `SLURM_CLUSTER_NAME` not defined, that means we didn't request an interactive node via SLURM before we launched the notebook and we are running on the main node!  So it's a good reminder also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662218c-2645-473a-9a6b-2a4baaa9d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ['SLURM_CLUSTER_NAME']=='denali':\n",
    "    cluster = SLURMCluster(processes=16, cores=16, memory='160GB', interface='ipogif0',\n",
    "                    project='woodshole', walltime='03:00:00',\n",
    "                    job_extra={'hint': 'multithread', 'exclusive':'user'})\n",
    "    cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05993de8-476f-4444-a4bf-b9ed81ccd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.environ['SLURM_CLUSTER_NAME']=='tallgrass':\n",
    "#    cluster = SLURMCluster(processes=1, cores=36, memory='370GB', interface='ib0',\n",
    "#                       project='woodshole', walltime='01:10:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cae714-b1ae-4ce8-8ef9-6cf0e2c7d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close(); cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75dd26-81b1-4b07-942d-d6e4dd74f39d",
   "metadata": {},
   "source": [
    "It turns out that on Tallgrass requesting 16 processes with one core each and specifying `exclusive=user` to stay on a node is the most efficient way to run this workflow. I previously tried `processes=1, cores=16` and the performance was terrible.  This isn't a compute intensive workflow, so those cores were just sitting around doing nothing, I guess.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feab96-1270-40a8-9493-0d6ba4d7f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ['SLURM_CLUSTER_NAME']=='tallgrass':\n",
    "    cluster = SLURMCluster(processes=1, cores=1, memory='10GB', \n",
    "                           interface='ib0',\n",
    "                       project='woodshole', walltime='04:00:00',\n",
    "                          job_extra={'hint': 'multithread', 'exclusive':'user'})\n",
    "    cluster.scale(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745a58b-f295-4e8a-b838-46965087bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e582579-e362-4ddf-9358-7ffd4fec61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f26903-7a1a-4419-98c3-99761bfa015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd000a-2f06-464c-8740-96366a9a4ef8",
   "metadata": {},
   "source": [
    "Determine how much memory each worker has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6accc86-1b15-41e9-9dd1-1449850a37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "148/16*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5a3bd-1812-486e-9f1e-0bc71cc865ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mem = '6.4GB'    # workers are 4GB, max_mem should be set to 75% or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b8b95-1b0a-4aad-a8a8-17f339876cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds2d = xr.open_dataset(flist[0], chunks={})   # open just one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac31cb-9dd7-4fd3-95e5-dd8534728765",
   "metadata": {},
   "source": [
    "#### Exploring the data a bit before rechunking\n",
    "Let's take a look at a few files.  open_mfdataset doesn't do well with lots of files (e.g. 1000s) but 144 should be not too bad.  Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888025d9-ff1a-4d32-86af-6e8564b247db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds2d = xr.open_mfdataset(flist[:144], concat_dim='Time', combine='nested',\n",
    "                         parallel=True, coords=\"minimal\", data_vars=\"minimal\", \n",
    "                         compat='override', chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d8682-ba4d-4ab9-8c41-32cea716bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.T2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011714e-56f7-467f-8cea-e61de6a680e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.T2.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab1f1d-96b2-4d45-95cb-12d729491eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.assign_coords({'time':ds2d.XTIME})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847b44d-b91e-40c7-bb20-00adbd24f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.SMCWTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797de5e-dc7d-475a-a340-9699f1b8da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds2d.SWDOWN[:,500,500].hvplot(x='time')\n",
    "b = ds2d.SWDNTC[:,500,500].hvplot(x='time')\n",
    "c = ds2d.SWDNBC[:,500,500].hvplot(x='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2e567-aad8-4475-867e-822b5188f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b * c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79381135-fe28-404d-bf3d-cfd76db86b4c",
   "metadata": {},
   "source": [
    "Good.  Seems that's okay.  So if we process the dataset in 144 time step chunks, we should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0cafbf-9e3e-4923-8c92-38b552ac036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48305e32-710e-4c08-beba-4bac0b80120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds2d.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1794127-67a4-46f3-be7b-5c87229738d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.T2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235fd28-f4d5-40c0-89eb-440935e14368",
   "metadata": {},
   "source": [
    "The `.encoding` attribute should tell us what type of compression and chunking the input NetCDF files have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddde8e2-7545-4129-ad26-21e50f43868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2d.T2.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2247c2a-517f-47f5-bf4a-ab2344a9ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rechunker_wrapper(source_store, target_store, temp_store, chunks=None,\n",
    "                      mem=None, consolidated=False, verbose=True):\n",
    "\n",
    "    if isinstance(source_store, xr.Dataset):\n",
    "        g = source_store  # trying to work directly with a dataset\n",
    "        ds_chunk = g\n",
    "    else:\n",
    "        g = zarr.group(str(source_store))\n",
    "        # get the correct shape from loading the store as xr.dataset and parse the chunks\n",
    "        ds_chunk = xr.open_zarr(str(source_store))\n",
    "        \n",
    "\n",
    "    group_chunks = {}\n",
    "    # newer tuple version that also takes into account when specified chunks are larger than the array\n",
    "    for var in ds_chunk.variables:\n",
    "        # pick appropriate chunks from above, and default to full length chunks for dimensions that are not in `chunks` above.\n",
    "        group_chunks[var] = []\n",
    "        for di in ds_chunk[var].dims:\n",
    "            if di in chunks.keys():\n",
    "                if chunks[di] > len(ds_chunk[di]):\n",
    "                    group_chunks[var].append(len(ds_chunk[di]))\n",
    "                else:\n",
    "                    group_chunks[var].append(chunks[di])\n",
    "\n",
    "            else:\n",
    "                group_chunks[var].append(len(ds_chunk[di]))\n",
    "\n",
    "        group_chunks[var] = tuple(group_chunks[var])\n",
    "    if verbose:\n",
    "        print(f\"Rechunking to: {group_chunks}\")\n",
    "        print(f\"mem:{mem}\")\n",
    "    rechunked = rechunker.rechunk(g, target_chunks=group_chunks, max_mem=mem,\n",
    "                                  target_store=target_store, temp_store=temp_store)\n",
    "    rechunked.execute(retries=10)\n",
    "    if consolidated:\n",
    "        if verbose:\n",
    "            print('consolidating metadata')\n",
    "        zarr.convenience.consolidate_metadata(target_store)\n",
    "    if verbose:\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e4681-3a80-42da-8a69-47ad9bfa1379",
   "metadata": {},
   "source": [
    "#### these paths need to be something you have write access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c3ada-b66a-4df9-ad7d-10b81a20df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_store = '/caldera/projects/usgs/water/zarr/conus404_chunk'\n",
    "temp_store = '/caldera/projects/usgs/water/zarr/tmp'\n",
    "concat_store = '/caldera/projects/usgs/water/zarr/conus404_2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc6de0-1915-4065-9480-88cd7b5d6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    fs.rm(concat_store, recursive=True)\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce507f9e-5557-416a-80ad-dabc31e6a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_chunk = 144\n",
    "x_chunk = 300\n",
    "y_chunk = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56fd74-3b0c-4d1b-8536-1940422ae661",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_chunks = int(len(flist)/time_chunk)\n",
    "print(n_time_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026b227-ca9b-4e4e-81ed-12bd08c033a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "\n",
    "for in in range(0,n_time_chunks):\n",
    "#for i in range(42,n_time_chunks): # if bombs or stops before completion\n",
    "    i0 = i * time_chunk\n",
    "    i1 = (i+1) * time_chunk\n",
    "    end = time.time()\n",
    "    print(i,flist[i0], (end-start)/60.)\n",
    "    ds2d = xr.open_mfdataset(flist[i0:i1], concat_dim='Time', combine='nested',\n",
    "                         parallel=True, coords=\"minimal\", data_vars=\"minimal\", \n",
    "                         compat='override', chunks={})\n",
    "    ds2d.assign_coords({'time':ds2d.XTIME})\n",
    "    # rechunker requires empty tmp and target dirs \n",
    "    try:\n",
    "        fs.rm(temp_store, recursive=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        fs.rm(target_store, recursive=True)\n",
    "    except:\n",
    "        pass\n",
    "  \n",
    "    time.sleep(3)  # wait for files to be removed (necessary? hack!)\n",
    "    \n",
    "\n",
    "    rechunker_wrapper(ds2d[vars], target_store=target_store, temp_store=temp_store, \n",
    "            mem=max_mem, consolidated=True, verbose=False,\n",
    "            chunks={'Time':time_chunk, 'south_north':y_chunk, 'west_east':x_chunk})\n",
    "    \n",
    "        # read back in the zarr chunk rechunker wrote\n",
    "    ds = xr.open_dataset(target_store, engine='zarr', backend_kwargs=dict(consolidated=True))\n",
    "\n",
    "    if i==0:\n",
    "        ds.to_zarr(concat_store, consolidated=False, mode='w')\n",
    "    else:\n",
    "        ds.to_zarr(concat_store, consolidated=False, append_dim='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd3fddb-208a-458e-b0f5-cb5f25b773ed",
   "metadata": {},
   "source": [
    "### Inspect the concatenated Zarr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89837d6-a6a9-4eba-bd1c-97b1d18d17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = '/caldera/projects/usgs/hazards/cmgp/woodshole/rsignell/zarr/conus404a'\n",
    "url = concat_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfc09d-4a50-4536-950f-f4798f87a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = xr.open_dataset(fs.get_mapper(url), engine='zarr', chunks={}, \n",
    "                     backend_kwargs=dict(consolidated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420bb5b-799b-47ef-b2dc-de8a76abf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.T2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd8982-9584-45a6-b212-46958576598e",
   "metadata": {},
   "source": [
    "How many time chunks do we have?  If less than the full amount, change the starting index for the loop above to this value and rerun the loop cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db85e17-3cb8-41f9-8399-c14fb5c8f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(ds.Time)/time_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20c2cf-e44c-49d6-867b-81e47a50c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.T2.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81982cd-5495-4b27-9345-feaca61b62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.T2[:,500,500].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
